# Tracking and Amplifying Linguistic Ambiguity in LLM-Generated Connections Puzzles

This repository contains the code, data, and evaluation framework described in the paper:

**"Tracking and Amplifying Linguistic Ambiguity in LLM-Generated Connections Puzzles"**

We define a taxonomy of linguistic ambiguity (polysemy, homonymy, idiomatic, syntactic, figurative) and propose a three-stage pipeline leveraging Chain-of-Thought prompting and ReAct-based external validation to generate and evaluate puzzles.

## ğŸ“Œ Features

- Taxonomy of ambiguity types
- Puzzle generation pipeline (Least-to-Most â†’ ReAct â†’ Reverse CoT)
- Automatic ambiguity metrics (sense count, ambiguous word ratio, stagewise growth)
- Prompt engineering for controlled ambiguity injection

## ğŸ› ï¸ Code Structure

- `pipeline/` â€“ Puzzle generation and validation pipeline (Python scripts)
- `data/` â€“ Sample puzzles, ambiguity logs, WordNet outputs
- `prompts/` â€“ Prompt templates for CoT, ReAct, RCoT
- `metrics/` â€“ Evaluation scripts and metric computation
- `notebooks/` â€“ Jupyter notebooks for analysis and visualization

## ğŸ“Š Example Output

- Puzzle with 4 groups, each with ambiguity annotations
- Chain of Thought trace with external validation log

## ğŸ§  Citation

Coming soon (ACL submission)
